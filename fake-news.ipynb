{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-14T14:09:47.897169Z","iopub.execute_input":"2021-11-14T14:09:47.898112Z","iopub.status.idle":"2021-11-14T14:09:47.907807Z","shell.execute_reply.started":"2021-11-14T14:09:47.898044Z","shell.execute_reply":"2021-11-14T14:09:47.906841Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"#change the path accordingly\ndf=pd.read_csv('/kaggle/input/fake-news/train.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:17:36.905165Z","iopub.execute_input":"2021-11-14T15:17:36.905456Z","iopub.status.idle":"2021-11-14T15:17:38.469633Z","shell.execute_reply.started":"2021-11-14T15:17:36.905424Z","shell.execute_reply":"2021-11-14T15:17:38.469047Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"#remove the rows which has nan values present in a column\nprint(df.isna().sum())\nprint(df.shape)\nprint(\"---\"*5)\nfor i,j in df.isna().sum().items():\n    print(f'{i :{10}}   {j/df.shape[0]}')\nprint(\"---\"*5)\ndf=df.dropna()\nprint(df.isna().sum())\nprint(df.shape)\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:18:05.845384Z","iopub.execute_input":"2021-11-14T15:18:05.846278Z","iopub.status.idle":"2021-11-14T15:18:05.893877Z","shell.execute_reply.started":"2021-11-14T15:18:05.846231Z","shell.execute_reply":"2021-11-14T15:18:05.893009Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:18:10.010498Z","iopub.execute_input":"2021-11-14T15:18:10.011105Z","iopub.status.idle":"2021-11-14T15:18:10.023483Z","shell.execute_reply.started":"2021-11-14T15:18:10.011048Z","shell.execute_reply":"2021-11-14T15:18:10.022690Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:18:21.200046Z","iopub.execute_input":"2021-11-14T15:18:21.200341Z","iopub.status.idle":"2021-11-14T15:18:21.206617Z","shell.execute_reply.started":"2021-11-14T15:18:21.200308Z","shell.execute_reply":"2021-11-14T15:18:21.205768Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"#for computational constraints\ndf=df.iloc[:10000,:]\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:18.622736Z","iopub.execute_input":"2021-11-14T15:19:18.623788Z","iopub.status.idle":"2021-11-14T15:19:18.629884Z","shell.execute_reply.started":"2021-11-14T15:19:18.623719Z","shell.execute_reply":"2021-11-14T15:19:18.628925Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"x=df[['title','author','text']]\nprint(x.shape)\ny=df['label']\nprint(y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:21.562407Z","iopub.execute_input":"2021-11-14T15:19:21.563262Z","iopub.status.idle":"2021-11-14T15:19:21.576681Z","shell.execute_reply.started":"2021-11-14T15:19:21.563210Z","shell.execute_reply":"2021-11-14T15:19:21.575611Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"#Exploratory data analysis\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nax = sns.countplot(x=df['label'])\n\nax.bar_label(container=ax.containers[0], labels=['reliable','unreliable'])\nplt.show()\n\n#1: unreliable\n#0: reliable\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:24.297373Z","iopub.execute_input":"2021-11-14T15:19:24.297682Z","iopub.status.idle":"2021-11-14T15:19:24.492079Z","shell.execute_reply.started":"2021-11-14T15:19:24.297650Z","shell.execute_reply":"2021-11-14T15:19:24.491204Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"#author description\ndf['author'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:29.595593Z","iopub.execute_input":"2021-11-14T15:19:29.595893Z","iopub.status.idle":"2021-11-14T15:19:29.608431Z","shell.execute_reply.started":"2021-11-14T15:19:29.595857Z","shell.execute_reply":"2021-11-14T15:19:29.607094Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"markdown","source":"# Top 10 author's whose news are more reliable and top 10 authors whose news are not at all reliable\n","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nreliable_author=list(df[df['label']==1]['author'])\nprint(type(Counter(reliable_author)))\nreliable_author_dict=Counter(reliable_author)\nreliable_author_dict=sorted(reliable_author_dict.items(), key=lambda i: i[1], reverse=True)[:10]\nprint(\"Top 10 reliable author's   :\",reliable_author_dict)\nprint(\"---\"*10)\nunreliable_author=list(df[df['label']==0]['author'])\nprint(type(Counter(unreliable_author)))\nunreliable_author_dict=Counter(unreliable_author)\nunreliable_author_dict=sorted(unreliable_author_dict.items(), key=lambda i: i[1], reverse=True)[:10]\nprint(\"Top 10 unreliable author's   :\",unreliable_author_dict)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:31.725389Z","iopub.execute_input":"2021-11-14T15:19:31.725704Z","iopub.status.idle":"2021-11-14T15:19:31.742535Z","shell.execute_reply.started":"2021-11-14T15:19:31.725668Z","shell.execute_reply":"2021-11-14T15:19:31.741821Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"**Some statistics related to  the text**","metadata":{}},{"cell_type":"code","source":"df['text'].describe()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:34.612204Z","iopub.execute_input":"2021-11-14T15:19:34.613220Z","iopub.status.idle":"2021-11-14T15:19:34.696267Z","shell.execute_reply.started":"2021-11-14T15:19:34.613172Z","shell.execute_reply":"2021-11-14T15:19:34.695463Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"#top words present in the text\nlist1=[]\nfor i in df['text']:\n    for j in i.split():\n        list1.append(j)\nwords_freq=Counter(list1)\nwords_top10=sorted(words_freq.items(), key=lambda i: i[1], reverse=True)[:50]\nprint(\"Top 10 words in texts   :\",words_top10)\n\n# thus removing stop words is mandatory because most of the top words present are stopwords\n    \n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:36.914171Z","iopub.execute_input":"2021-11-14T15:19:36.914721Z","iopub.status.idle":"2021-11-14T15:19:40.546200Z","shell.execute_reply.started":"2021-11-14T15:19:36.914665Z","shell.execute_reply":"2021-11-14T15:19:40.544717Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2021-11-14T14:09:58.851871Z","iopub.execute_input":"2021-11-14T14:09:58.852232Z","iopub.status.idle":"2021-11-14T14:09:58.857926Z","shell.execute_reply.started":"2021-11-14T14:09:58.852191Z","shell.execute_reply":"2021-11-14T14:09:58.856818Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# data preprocessing \ndf['combine']=df['title'] + \" \"+df['author']+ \" \" + df['text']\ndf.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:45.137786Z","iopub.execute_input":"2021-11-14T15:19:45.138096Z","iopub.status.idle":"2021-11-14T15:19:45.244530Z","shell.execute_reply.started":"2021-11-14T15:19:45.138063Z","shell.execute_reply":"2021-11-14T15:19:45.243431Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"df=df[['label','combine']].reset_index()\ndf=df.iloc[:,1:]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:19:57.262813Z","iopub.execute_input":"2021-11-14T15:19:57.263379Z","iopub.status.idle":"2021-11-14T15:19:57.277308Z","shell.execute_reply.started":"2021-11-14T15:19:57.263342Z","shell.execute_reply":"2021-11-14T15:19:57.276563Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"text=df['combine'].copy()\ntext.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:20:00.260728Z","iopub.execute_input":"2021-11-14T15:20:00.261070Z","iopub.status.idle":"2021-11-14T15:20:00.270327Z","shell.execute_reply.started":"2021-11-14T15:20:00.261034Z","shell.execute_reply":"2021-11-14T15:20:00.269089Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport re\nfrom nltk.corpus import stopwords\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:20:02.984863Z","iopub.execute_input":"2021-11-14T15:20:02.985611Z","iopub.status.idle":"2021-11-14T15:20:02.989363Z","shell.execute_reply.started":"2021-11-14T15:20:02.985563Z","shell.execute_reply":"2021-11-14T15:20:02.988742Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nSTOPWORDS = set(stopwords.words('english'))\nprint(STOPWORDS)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:20:13.954891Z","iopub.execute_input":"2021-11-14T15:20:13.955252Z","iopub.status.idle":"2021-11-14T15:20:13.963806Z","shell.execute_reply.started":"2021-11-14T15:20:13.955217Z","shell.execute_reply":"2021-11-14T15:20:13.962814Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"text1=\"Jalal eating eat good best 0=== engineer \"\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nps = PorterStemmer()\nlemmatizer = WordNetLemmatizer()\n\ncorpus = []\nfor i in range(0, 1):\n    review = re.sub('[^a-zA-Z]', ' ', text1).strip().lower()\n\n    \n    review = [ps.stem(word) for word in review.split() if not word in stopwords.words('english')]\n    print(review)\n    review = [lemmatizer.lemmatize(word) for word in review ]\n    print(review)\n    review = ' '.join(review)\n    corpus.append(review)\ncorpus","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:20:17.933368Z","iopub.execute_input":"2021-11-14T15:20:17.934432Z","iopub.status.idle":"2021-11-14T15:20:17.947652Z","shell.execute_reply.started":"2021-11-14T15:20:17.934372Z","shell.execute_reply":"2021-11-14T15:20:17.946725Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"len(text)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:20:22.636983Z","iopub.execute_input":"2021-11-14T15:20:22.637504Z","iopub.status.idle":"2021-11-14T15:20:22.642707Z","shell.execute_reply.started":"2021-11-14T15:20:22.637459Z","shell.execute_reply":"2021-11-14T15:20:22.641837Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"#stemming and lemmatization\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\n\nps = PorterStemmer()\nlemmatizer = WordNetLemmatizer()\n\ncorpus = []\nfor i in range(0, len(text)):\n    review = re.sub('[^a-zA-Z]', ' ', text[i]).strip().lower()\n    \n    review = [word for word in review.split() if not word in stopwords.words('english')]\n    #add lemmatizaion with stemming\n    review = [lemmatizer.lemmatize(word) for word in review ]\n    \n    review = ' '.join(review)\n\n    print(i)\n    print(\"----\")\n    \n    corpus.append(review)\nprint(len(corpus))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2021-11-14T16:56:35.894265Z","iopub.execute_input":"2021-11-14T16:56:35.894597Z","iopub.status.idle":"2021-11-14T16:56:35.900323Z","shell.execute_reply.started":"2021-11-14T16:56:35.894552Z","shell.execute_reply":"2021-11-14T16:56:35.899182Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"voc_size=5000","metadata":{"execution":{"iopub.status.busy":"2021-11-14T15:45:52.230468Z","iopub.execute_input":"2021-11-14T15:45:52.230809Z","iopub.status.idle":"2021-11-14T15:45:52.234956Z","shell.execute_reply.started":"2021-11-14T15:45:52.230734Z","shell.execute_reply":"2021-11-14T15:45:52.234101Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"onehot_representation=[one_hot(words,voc_size)for words in corpus] \nprint(len(onehot_representation))\n\nsent_length=50\nembedded_docs=pad_sequences(onehot_representation,padding='post',maxlen=sent_length)\nprint(len(embedded_docs))","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:11:00.867139Z","iopub.execute_input":"2021-11-14T17:11:00.867986Z","iopub.status.idle":"2021-11-14T17:11:03.024562Z","shell.execute_reply.started":"2021-11-14T17:11:00.867944Z","shell.execute_reply":"2021-11-14T17:11:03.023693Z"},"trusted":true},"execution_count":128,"outputs":[]},{"cell_type":"code","source":"print(onehot_representation[0])","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:11:08.217634Z","iopub.execute_input":"2021-11-14T17:11:08.217944Z","iopub.status.idle":"2021-11-14T17:11:08.223470Z","shell.execute_reply.started":"2021-11-14T17:11:08.217915Z","shell.execute_reply":"2021-11-14T17:11:08.222400Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"## Creating model and add two lstm layers\nembedding_vector_features=100\nmodel=Sequential()\nmodel.add(Embedding(voc_size,embedding_vector_features,input_length=sent_length))\nmodel.add(LSTM(100,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(100))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nprint(model.summary())\n","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:11:25.452260Z","iopub.execute_input":"2021-11-14T17:11:25.453020Z","iopub.status.idle":"2021-11-14T17:11:26.089910Z","shell.execute_reply.started":"2021-11-14T17:11:25.452982Z","shell.execute_reply":"2021-11-14T17:11:26.088943Z"},"trusted":true},"execution_count":130,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nX=np.array(embedded_docs).copy()\ny=np.array(list(df['label']))\nprint(X.shape,y.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T16:09:16.978733Z","iopub.execute_input":"2021-11-14T16:09:16.979063Z","iopub.status.idle":"2021-11-14T16:09:17.009044Z","shell.execute_reply.started":"2021-11-14T16:09:16.979030Z","shell.execute_reply":"2021-11-14T16:09:17.008097Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\nprint(X_train.shape,y_train.shape)\nprint(X_test.shape,y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T16:10:32.967743Z","iopub.execute_input":"2021-11-14T16:10:32.968120Z","iopub.status.idle":"2021-11-14T16:10:32.985228Z","shell.execute_reply.started":"2021-11-14T16:10:32.968078Z","shell.execute_reply":"2021-11-14T16:10:32.984178Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"#fit the model\nhistory=model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=5,batch_size=128)\nhistory","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:12:38.203976Z","iopub.execute_input":"2021-11-14T17:12:38.204931Z","iopub.status.idle":"2021-11-14T17:22:19.878004Z","shell.execute_reply.started":"2021-11-14T17:12:38.204876Z","shell.execute_reply":"2021-11-14T17:22:19.876664Z"},"trusted":true},"execution_count":132,"outputs":[]},{"cell_type":"code","source":"#plot the training and validation accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:31:33.999059Z","iopub.execute_input":"2021-11-14T17:31:33.999380Z","iopub.status.idle":"2021-11-14T17:31:34.182857Z","shell.execute_reply.started":"2021-11-14T17:31:33.999349Z","shell.execute_reply":"2021-11-14T17:31:34.181804Z"},"trusted":true},"execution_count":138,"outputs":[]},{"cell_type":"code","source":"y_pred=model.predict(X_test)\ny_pred","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:23:17.651778Z","iopub.execute_input":"2021-11-14T17:23:17.652072Z","iopub.status.idle":"2021-11-14T17:23:37.209927Z","shell.execute_reply.started":"2021-11-14T17:23:17.652041Z","shell.execute_reply":"2021-11-14T17:23:37.208862Z"},"trusted":true},"execution_count":133,"outputs":[]},{"cell_type":"code","source":"#function to predict class\ndef predict_class(y_pred):\n    pred_list=[]\n    for i in y_pred:\n        if i >0.5:\n            pred_list.append(1)\n        else:\n            pred_list.append(0)\n    return pred_list\n        \n        \nprediction=predict_class(y_pred)   \nconfusion_matrix(y_test,prediction)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:23:50.664799Z","iopub.execute_input":"2021-11-14T17:23:50.665509Z","iopub.status.idle":"2021-11-14T17:23:50.680563Z","shell.execute_reply.started":"2021-11-14T17:23:50.665467Z","shell.execute_reply":"2021-11-14T17:23:50.679955Z"},"trusted":true},"execution_count":135,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test,prediction)","metadata":{"execution":{"iopub.status.busy":"2021-11-14T17:23:54.772689Z","iopub.execute_input":"2021-11-14T17:23:54.775033Z","iopub.status.idle":"2021-11-14T17:23:54.782208Z","shell.execute_reply.started":"2021-11-14T17:23:54.774949Z","shell.execute_reply":"2021-11-14T17:23:54.781245Z"},"trusted":true},"execution_count":136,"outputs":[]}]}